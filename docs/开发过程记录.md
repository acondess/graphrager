# 开发过程记录

## 2024-12-16

### 项目初始化
- 创建了项目目录结构，包括 `frontend` 和 `backend` 目录。
- 在 `backend` 目录下创建了基本的 Flask 应用，文件为 `app.py`。
- 在 `frontend` 目录下创建了基本的 HTML、CSS 和 JavaScript 文件。

### 后端开发
1. **基础设置**
   - 使用 Flask 框架搭建基本的 Web 服务器
   - 添加了静态文件服务功能
   - 实现了根路径路由，提供前端 HTML 文件

2. **知识图谱生成功能**
   - 实现了 `/generate` 接口，处理 POST 请求
   - 添加了 URL 验证和规范化功能
   - 使用 BeautifulSoup 解析网页内容
   - 实现了实体和关系提取算法
   - 添加了详细的错误处理和日志记录
   - 优化了 HTTP 请求配置，添加超时和用户代理

### 前端开发
1. **用户界面**
   - 创建了响应式布局
   - 添加了 URL 输入框和操作按钮
   - 实现了加载状态指示器
   - 添加了错误提示显示
   - 优化了整体视觉风格

2. **图谱可视化**
   - 从 Graphrag 切换到 vis.js 库
   - 实现了交互式知识图谱显示
   - 添加了节点点击事件和详情显示
   - 实现了图谱缩放和拖拽功能
   - 添加了图谱控制按钮（缩放、适应）
   - 优化了节点和边的样式

3. **数据展示**
   - 添加了图谱统计信息显示
   - 实现了节点列表展示
   - 添加了可点击的 URL 链接
   - 优化了信息的展示方式

### 遇到的问题和解决方案
1. **后端问题**
   - 问题：HTTP 500 错误
   - 解决：完善了错误处理，添加了详细的日志记录
   - 问题：URL 处理不完整
   - 解决：添加了 URL 验证和规范化功能

2. **前端问题**
   - 问题：图谱库兼容性问题（vis is not defined）
   - 解决：从 Graphrag 切换到更稳定的 vis.js 库
   - 问题：图谱交互不完整
   - 解决：添加了完整的交互功能和事件处理

### 当前功能
1. **URL 处理**
   - 支持输入任意 URL
   - 自动验证 URL 格式
   - 处理相对和绝对 URL

2. **知识图谱生成**
   - 提取网页中的链接作为节点
   - 建立节点之间的关系
   - 限制最大节点数量为 50

3. **图谱可视化**
   - 交互式图谱显示
   - 节点点击查看详情
   - 支持缩放和拖拽
   - 显示节点统计信息

### 下一步计划
1. **页面分析与实体识别策略**
   - **页面类型分析**
     - 识别页面是否为结构化的门户页面（如导航页、目录页）
     - 识别页面是否为包含详细内容的文章页面
     - 根据页面特征选择不同的处理策略

   - **门户页面处理策略**
     - 重点提取导航链接和分类信息
     - 识别菜单结构和层级关系
     - 提取页面的组织结构特征
     - 建立分类体系的关系图谱

   - **内容页面处理策略**
     - 提取正文内容中的关键实体
     - 识别段落间的逻辑关系
     - 提取引用和参考关系
     - 构建内容主题的知识网络

2. **实体识别增强**
   - 添加命名实体识别（NER）功能
   - 识别人名、地名、组织机构等实体
   - 提取时间和数字类型的实体
   - 识别专业术语和关键概念

3. **关系提取优化**
   - 基于页面类型选择关系提取策略
   - 增加语义分析以提取实体间关系
   - 构建更丰富的关系类型系统
   - 提高关系提取的准确性

4. **用户体验优化**
   - 添加页面类型自动识别提示
   - 优化不同类型页面的图谱展示方式
   - 添加图谱布局切换选项
   - 支持图谱数据导出功能

5. **技术实现计划**
   - 集成自然语言处理库
   - 实现页面类型识别算法
   - 优化数据存储和处理效率
   - 添加批量处理功能

6. **代码优化**
   - 重构代码提高可维护性
   - 添加单元测试
   - 优化错误处理机制
   - 改进日志记录系统

## 2024-12-16 - 大模型集成计划

### 集成本地大模型
1. **环境准备**
   - 选择合适的本地大模型（如 LLaMA、ChatGLM）
   - 配置模型运行环境
   - 准备必要的硬件资源

2. **模型服务搭建**
   - 搭建模型推理服务
   - 配置 API 接口
   - 实现模型调用的封装类

3. **页面分析功能**
   - **Prompt 设计**
     - 设计页面类型识别的 prompt
     - 设计实体提取的 prompt
     - 设计关系识别的 prompt
   
   - **页面类型分析**
     ```python
     # 示例 prompt
     """
     分析以下网页内容的类型，判断是否为：
     1. 结构化的门户页面（包含主要为导航、目录等）
     2. 详细内容页面（包含文章、详细描述等）
     
     返回格式：
     {
         "type": "portal|content",
         "confidence": 0.95,
         "features": ["feature1", "feature2"]
     }
     
     网页内容：
     {content}
     """
     ```

   - **实体关系提取**
     ```python
     # 示例 prompt
     """
     根据页面类型，提取以下内容中的实体和关系：
     
     对于门户页面：
     - 提取导航结构
     - 识别分类体系
     - 提取组织架构
     
     对于内容页面：
     - 提取关键概念
     - 识别实体关系
     - 提取引用关系
     
     返回格式：
     {
         "entities": [
             {"id": "e1", "type": "concept|person|org", "name": "实体名称"}
         ],
         "relations": [
             {"source": "e1", "target": "e2", "type": "包含|引用|属于"}
         ]
     }
     
     页面内容：
     {content}
     """
     ```

4. **后端改造**
   - 添加模型服务客户端
   - 实现模型调用接口
   - 优化数据处理流程
   ```python
   class LLMClient:
       def __init__(self, model_endpoint):
           self.endpoint = model_endpoint
           
       async def analyze_page_type(self, content):
           # 调用模型进行页面类型分析
           pass
           
       async def extract_entities_relations(self, content, page_type):
           # 根据页面类型提取实体和关系
           pass
   ```

5. **前端优化**
   - 添加页面分析状态显示
   - 优化图谱展示效果
   - 添加分析结果解释

6. **性能优化**
   - 实现模型结果缓存
   - 优化请求并发处理
   - 添加任务队列管理

### 下一步具体实施计划
1. **第一阶段：环境搭建**
   - 选择并下载合适的模型
   - 配置 Python 环境
   - 测试模型基本功能

2. **第二阶段：接口开发**
   - 实现模型服务封装
   - 开发页面分析接口
   - 开发实体关系提取接口

3. **第三阶段：功能集成**
   - 集成到现有后端系统
   - 优化前端交互体验
   - 完善错误处理机制

4. **第四阶段：测试优化**
   - 进行性能测试
   - 优化响应速度
   - 提高分析准确率

## 2024-12-16 - 大模型集成实现

### 1. 环境配置
- 使用 Ollama 作为本地大模型服务
- 选择 llama3:latest 模型用于知识图谱生成
- 配置了必要的 Python 依赖：
  ```
  flask==3.0.0
  flask-cors==4.0.0
  requests==2.31.0
  beautifulsoup4==4.12.2
  python-dotenv==1.0.0
  ```

### 2. 后端架构实现
1. **LLM 客户端封装**
   - 创建 `backend/llm_client.py`
   - 实现 OllamaClient 类
   - 封装了模型调用接口
   - 实现了页面分析和实体提取功能

2. **API 设计**
   - `/analyze` 端点：接收 URL，返回页面分析结果
   - 支持页面类型识别
   - 支持实体关系提取

3. **提示词设计**
   ```python
   # 页面类型分析
   {
       "type": "portal|content",
       "confidence": 0.95,
       "features": ["feature1", "feature2"]
   }

   # 实体关系提取
   {
       "entities": [
           {"id": "e1", "type": "concept|person|org", "name": "实体名称"}
       ],
       "relations": [
           {"source": "e1", "target": "e2", "type": "包含|引用|属于"}
       ]
   }
   ```

### 3. 项目结构
```
Graphrager/
├── backend/
│   ├── __init__.py
│   ├── app.py          # Flask 应用主文件
│   └── llm_client.py   # Ollama 客户端封装
├── frontend/
│   ├── index.html
│   ├── script.js
│   └── styles.css
├── docs/
│   └── ollama_setup.md # Ollama 安装配置文档
├── .env                # 环境变量配置
└── requirements.txt    # Python 依赖
```

### 4. 处理流程
1. 接收用户输入的 URL
2. 获取网页内容
3. 使用 LLM 分析页面类型
4. 根据页面类型提取实体和关系
5. 返回结构化数据用于图谱展示

### 下一步计划
1. **模型调优**
   - 优化提示词设计
   - 调整参数配置
   - 提高实体识别准确率

2. **性能优化**
   - 实现结果缓存
   - 优化响应速度
   - 处理大规模文本

3. **功能扩展**
   - 支持批量 URL 处理
   - 添加更多实体类型
   - 优化关系抽取逻辑
